{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as seabornInstance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big5\n"
     ]
    }
   ],
   "source": [
    "import chardet    \n",
    "rawdata = open('source.csv', 'rb').read()\n",
    "result = chardet.detect(rawdata)\n",
    "charenc = result['encoding']\n",
    "print(charenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('source.csv',encoding=r'Big5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       08~10\n",
       "1       00~02\n",
       "2       00~02\n",
       "3       06~08\n",
       "4       10~12\n",
       "        ...  \n",
       "3267    09~11\n",
       "3268    12~14\n",
       "3269    06~08\n",
       "3270    15~17\n",
       "3271    18~20\n",
       "Name: 發生時段, Length: 3272, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['發生時段']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_zone = []\n",
    "for r in df['發生時段']:\n",
    "    if(r == '00~02' or r == '03~05' or r == '04~06' or r == '05~07'):\n",
    "        time_zone.append('midnight')\n",
    "    elif(r == '06~08' or r =='08~10' or r == '09~11' or r == '10~12' or r == '11~13'):\n",
    "        time_zone.append('morning')\n",
    "    elif(r == '12~14' or r == '14~16' or r == '15~17' or r == '15~18' or r == '16~18' or r == '17~19'):\n",
    "        time_zone.append('afternoon')\n",
    "    else:\n",
    "        time_zone.append('night')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_zone'] = time_zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['time_zone']=='morning'].to_csv('morning.csv',encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in df['發生地點']:\n",
    "    list.append(r[0:6])\n",
    "df['locate'] = list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW_vectorizer = CountVectorizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW_vectorizer.fit(train['locate'])\n",
    "train_data_BOW_features = BOW_vectorizer.transform(train['locate'])\n",
    "test_data_BOW_features = BOW_vectorizer.transform(test['locate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2617x12 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2617 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_BOW_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['臺北市中山區',\n",
       " '臺北市中正區',\n",
       " '臺北市信義區',\n",
       " '臺北市內湖區',\n",
       " '臺北市北投區',\n",
       " '臺北市南港區',\n",
       " '臺北市士林區',\n",
       " '臺北市大同區',\n",
       " '臺北市大安區',\n",
       " '臺北市文山區',\n",
       " '臺北市松山區',\n",
       " '臺北市萬華區']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = BOW_vectorizer.get_feature_names()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ASUS\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.606 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2617, 1405)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import jieba\n",
    "# build analyzers (bag-of-words)\n",
    "BOW = CountVectorizer(tokenizer=jieba.cut) \n",
    "\n",
    "# apply analyzer to training data\n",
    "BOW.fit(train['發生地點'])\n",
    "\n",
    "train_data_BOW_features = BOW.transform(train['time_zone'])\n",
    "\n",
    "## check dimension\n",
    "train_data_BOW_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = BOW.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (2617, 1405)\n",
      "y_train.shape:  (2617,)\n",
      "X_test.shape:  (655, 1405)\n",
      "y_test.shape:  (655,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# for a classificaiton problem, you need to provide both training & testing data\n",
    "X_train = BOW.transform(train['locate'])\n",
    "y_train = train['time_zone']\n",
    "\n",
    "X_test = BOW.transform(test['locate'])\n",
    "y_test = test['time_zone']\n",
    "\n",
    "## take a look at data dimension is a good habbit  :)\n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['morning', 'night', 'night', 'night', 'night', 'night', 'morning',\n",
       "       'night', 'night', 'night', 'night', 'night', 'afternoon', 'night',\n",
       "       'night', 'night', 'afternoon', 'night', 'night', 'morning'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## build DecisionTree model\n",
    "DT_model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "## training!\n",
    "DT_model = DT_model.fit(X_train, y_train)\n",
    "\n",
    "## predict!\n",
    "y_train_pred = DT_model.predict(X_train)\n",
    "y_test_pred = DT_model.predict(X_test)\n",
    "\n",
    "## so we get the pred result\n",
    "y_test_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.34\n",
      "testing accuracy: 0.29\n"
     ]
    }
   ],
   "source": [
    "## accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_train = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
    "acc_test = accuracy_score(y_true=y_test, y_pred=y_test_pred)\n",
    "\n",
    "print('training accuracy: {}'.format(round(acc_train, 2)))\n",
    "print('testing accuracy: {}'.format(round(acc_test, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check label:  ['afternoon' 'midnight' 'morning' 'night']\n",
      "\n",
      "## Before convert\n",
      "y_train[0:4]:\n",
      " 1530       night\n",
      "1437       night\n",
      "1012     morning\n",
      "1720    midnight\n",
      "Name: time_zone, dtype: object\n",
      "\n",
      "y_train.shape:  (2617,)\n",
      "y_test.shape:  (655,)\n",
      "\n",
      "\n",
      "## After convert\n",
      "y_train[0:4]:\n",
      " [[0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]]\n",
      "\n",
      "y_train.shape:  (2617, 4)\n",
      "y_test.shape:  (655, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "print('check label: ', label_encoder.classes_)\n",
    "print('\\n## Before convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return np_utils.to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)\n",
    "y_test = label_encode(label_encoder, y_test)\n",
    "\n",
    "print('\\n\\n## After convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape:  1405\n",
      "output_shape:  4\n"
     ]
    }
   ],
   "source": [
    "# I/O check\n",
    "input_shape = X_train.shape[1]\n",
    "print('input_shape: ', input_shape)\n",
    "\n",
    "output_shape = len(label_encoder.classes_)\n",
    "print('output_shape: ', output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1405)]            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                89984     \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 94,404\n",
      "Trainable params: 94,404\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import ReLU, Softmax\n",
    "\n",
    "# input layer\n",
    "model_input = Input(shape=(input_shape, ))  # 500\n",
    "X = model_input\n",
    "\n",
    "# 1st hidden layer\n",
    "X_W1 = Dense(units=64)(X)  # 64\n",
    "H1 = ReLU()(X_W1)\n",
    "\n",
    "# 2nd hidden layer\n",
    "H1_W2 = Dense(units=64)(H1)  # 64\n",
    "H2 = ReLU()(H1_W2)\n",
    "\n",
    "# output layer\n",
    "H2_W3 = Dense(units=output_shape)(H2)  # 4\n",
    "H3 = Softmax()(H2_W3)\n",
    "\n",
    "model_output = H3\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=[model_input], outputs=[model_output])\n",
    "\n",
    "# loss function & optimizer\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# show model construction\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3267 - accuracy: 0.3412 - val_loss: 1.3612 - val_accuracy: 0.2947\n",
      "Epoch 2/25\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3275 - accuracy: 0.3408 - val_loss: 1.3616 - val_accuracy: 0.2947\n",
      "Epoch 3/25\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3269 - accuracy: 0.3389 - val_loss: 1.3610 - val_accuracy: 0.2885\n",
      "Epoch 4/25\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.3271 - accuracy: 0.3420 - val_loss: 1.3608 - val_accuracy: 0.2885\n",
      "Epoch 5/25\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.3269 - accuracy: 0.3420 - val_loss: 1.3615 - val_accuracy: 0.2885\n",
      "Epoch 6/25\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.3270 - accuracy: 0.3412 - val_loss: 1.3613 - val_accuracy: 0.2855\n",
      "Epoch 7/25\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3274 - accuracy: 0.3363 - val_loss: 1.3640 - val_accuracy: 0.2885\n",
      "Epoch 8/25\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3272 - accuracy: 0.3428 - val_loss: 1.3609 - val_accuracy: 0.2947\n",
      "Epoch 9/25\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3271 - accuracy: 0.3393 - val_loss: 1.3601 - val_accuracy: 0.2947\n",
      "Epoch 10/25\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3269 - accuracy: 0.3389 - val_loss: 1.3639 - val_accuracy: 0.2885\n",
      "Epoch 11/25\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3268 - accuracy: 0.3420 - val_loss: 1.3610 - val_accuracy: 0.2947\n",
      "Epoch 12/25\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3270 - accuracy: 0.3386 - val_loss: 1.3624 - val_accuracy: 0.2855\n",
      "Epoch 13/25\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3278 - accuracy: 0.3389 - val_loss: 1.3614 - val_accuracy: 0.2885\n",
      "Epoch 14/25\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3270 - accuracy: 0.3420 - val_loss: 1.3616 - val_accuracy: 0.2947\n",
      "Epoch 15/25\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3269 - accuracy: 0.3389 - val_loss: 1.3611 - val_accuracy: 0.2885\n",
      "Epoch 16/25\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3271 - accuracy: 0.3408 - val_loss: 1.3624 - val_accuracy: 0.2947\n",
      "Epoch 17/25\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.3269 - accuracy: 0.3412 - val_loss: 1.3627 - val_accuracy: 0.2947\n",
      "Epoch 18/25\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.3272 - accuracy: 0.3389 - val_loss: 1.3613 - val_accuracy: 0.2947\n",
      "Epoch 19/25\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3270 - accuracy: 0.3416 - val_loss: 1.3617 - val_accuracy: 0.2947\n",
      "Epoch 20/25\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3268 - accuracy: 0.3405 - val_loss: 1.3618 - val_accuracy: 0.2885\n",
      "Epoch 21/25\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3268 - accuracy: 0.3412 - val_loss: 1.3623 - val_accuracy: 0.2947\n",
      "Epoch 22/25\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3275 - accuracy: 0.3366 - val_loss: 1.3602 - val_accuracy: 0.2947\n",
      "Epoch 23/25\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3273 - accuracy: 0.3370 - val_loss: 1.3620 - val_accuracy: 0.2947\n",
      "Epoch 24/25\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3274 - accuracy: 0.3424 - val_loss: 1.3592 - val_accuracy: 0.2855\n",
      "Epoch 25/25\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3270 - accuracy: 0.3401 - val_loss: 1.3626 - val_accuracy: 0.2947\n",
      "training finish\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "# training setting\n",
    "epochs = 25\n",
    "batch_size = 128\n",
    "\n",
    "# training!\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size, \n",
    "                    validation_data = (X_test, y_test))\n",
    "print('training finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27878603, 0.0523066 , 0.3376779 , 0.33122948],\n",
       "       [0.32732227, 0.10465295, 0.22233465, 0.34569013],\n",
       "       [0.21700029, 0.19192323, 0.25186312, 0.33921337],\n",
       "       [0.24791259, 0.13043502, 0.28587985, 0.33577254],\n",
       "       [0.24791259, 0.13043502, 0.28587985, 0.33577254]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict\n",
    "pred_result = model.predict(X_test, batch_size=128)\n",
    "pred_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['morning', 'night', 'night', 'night', 'night'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result = label_decode(label_encoder, pred_result)\n",
    "pred_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy: 0.29\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('testing accuracy: {}'.format(round(accuracy_score(label_decode(label_encoder, y_test), pred_result), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---KNN---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data , test_data , train_label , test_label = train_test_split(df['locate'],df['time_zone'],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2617, 1405)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = BOW.transform(train_data)\n",
    "test_data = BOW.transform(test_data)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(655, 1405)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(train_data,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28091603053435116"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(test_data,test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---如何預測---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = BOW.transform(['乾你媽的'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'night'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_model.predict(test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['發生地點']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_bow = BOW.transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = DT_model.predict(target_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = pd.Series(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.concat([target,predict], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('result.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "380030d1298d5a27518acca789ff38fe82bbf2e68b73263de6a6bf23efb7704c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
